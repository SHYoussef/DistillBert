{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":2699749,"sourceType":"datasetVersion","datasetId":1644240}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport transformers\nfrom datasets import Dataset, DatasetDict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-17T23:52:32.920948Z","iopub.execute_input":"2024-08-17T23:52:32.921238Z","iopub.status.idle":"2024-08-17T23:52:39.039311Z","shell.execute_reply.started":"2024-08-17T23:52:32.921214Z","shell.execute_reply":"2024-08-17T23:52:39.038376Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:01.463602Z","iopub.execute_input":"2024-08-17T23:53:01.464216Z","iopub.status.idle":"2024-08-17T23:53:01.530757Z","shell.execute_reply.started":"2024-08-17T23:53:01.464186Z","shell.execute_reply":"2024-08-17T23:53:01.529971Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset =Dataset.from_pandas(train)\ntest_dataset = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:05.825590Z","iopub.execute_input":"2024-08-17T23:53:05.826414Z","iopub.status.idle":"2024-08-17T23:53:05.917093Z","shell.execute_reply.started":"2024-08-17T23:53:05.826379Z","shell.execute_reply":"2024-08-17T23:53:05.916121Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"new_dataset = train_dataset.train_test_split(test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:14.411087Z","iopub.execute_input":"2024-08-17T23:53:14.411921Z","iopub.status.idle":"2024-08-17T23:53:14.428877Z","shell.execute_reply.started":"2024-08-17T23:53:14.411884Z","shell.execute_reply":"2024-08-17T23:53:14.425607Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:16.093788Z","iopub.execute_input":"2024-08-17T23:53:16.094148Z","iopub.status.idle":"2024-08-17T23:53:17.768647Z","shell.execute_reply.started":"2024-08-17T23:53:16.094117Z","shell.execute_reply":"2024-08-17T23:53:17.767916Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baa1a31a78614461b7f9b835b3a31e86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce011eb367c14332aa99bae7e00cd18c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a03c15d8b4144074b40c6bce70908cd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6783f8b87d41d68afbcd999d5f571b"}},"metadata":{}}]},{"cell_type":"code","source":"new = new_dataset.rename_columns({\"target\":\"label\"})","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:21.209820Z","iopub.execute_input":"2024-08-17T23:53:21.210763Z","iopub.status.idle":"2024-08-17T23:53:21.220003Z","shell.execute_reply.started":"2024-08-17T23:53:21.210718Z","shell.execute_reply":"2024-08-17T23:53:21.219042Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def input_ids(batch):\n    return {\"input_ids\":tokenizer.encode(batch[\"text\"])}\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:21.944581Z","iopub.execute_input":"2024-08-17T23:53:21.944993Z","iopub.status.idle":"2024-08-17T23:53:21.949634Z","shell.execute_reply.started":"2024-08-17T23:53:21.944962Z","shell.execute_reply":"2024-08-17T23:53:21.948631Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"new = new.map(input_ids)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:23.755561Z","iopub.execute_input":"2024-08-17T23:53:23.755938Z","iopub.status.idle":"2024-08-17T23:53:26.237029Z","shell.execute_reply.started":"2024-08-17T23:53:23.755906Z","shell.execute_reply":"2024-08-17T23:53:26.236126Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6090 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58fd692d28ef46e5ab95efe85798fa65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1523 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff14d8a1dd2f49fd93a0547cf2e337da"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:53:26.238561Z","iopub.execute_input":"2024-08-17T23:53:26.239160Z","iopub.status.idle":"2024-08-17T23:53:29.956778Z","shell.execute_reply.started":"2024-08-17T23:53:26.239131Z","shell.execute_reply":"2024-08-17T23:53:29.956008Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5107dee07734a32a43e064d83675380"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n\ntraining_args = TrainingArguments(output_dir=model_name,\n num_train_epochs=3,\n learning_rate=2e-5,\n per_device_train_batch_size=32,\n per_device_eval_batch_size=32,\n weight_decay=0.01,\n evaluation_strategy=\"epoch\",\n disable_tqdm=False,\n push_to_hub=False,\n log_level=\"error\",\n report_to = \"none\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:54:24.222311Z","iopub.execute_input":"2024-08-17T23:54:24.223574Z","iopub.status.idle":"2024-08-17T23:54:24.257864Z","shell.execute_reply.started":"2024-08-17T23:54:24.223534Z","shell.execute_reply":"2024-08-17T23:54:24.256912Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:54:28.502845Z","iopub.execute_input":"2024-08-17T23:54:28.503493Z","iopub.status.idle":"2024-08-17T23:54:28.508634Z","shell.execute_reply.started":"2024-08-17T23:54:28.503459Z","shell.execute_reply":"2024-08-17T23:54:28.507706Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model, args=training_args,\n compute_metrics=compute_metrics,\n train_dataset=new[\"train\"],\n eval_dataset=new[\"test\"],\n tokenizer=tokenizer)\ntrainer.train();\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:54:39.980357Z","iopub.execute_input":"2024-08-17T23:54:39.981062Z","iopub.status.idle":"2024-08-17T23:56:57.345631Z","shell.execute_reply.started":"2024-08-17T23:54:39.981024Z","shell.execute_reply":"2024-08-17T23:56:57.344831Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 02:14, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.392675</td>\n      <td>0.839790</td>\n      <td>0.839483</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.391341</td>\n      <td>0.842416</td>\n      <td>0.841906</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.404911</td>\n      <td>0.838477</td>\n      <td>0.838440</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"test_new = test_dataset.map(input_ids)\ndef predict(batch):\n    tensor = torch.tensor(batch[\"input_ids\"]).to(device)\n    tensor = tensor.unsqueeze(0)\n    outputs = model(tensor)\n    \n    return {\"label\": outputs.logits.argmax(-1).to(device)}\ntest_new = test_new.map(predict)\ndicts = {\"id\": test[\"id\"].values,\"target\":np.array(test_new[\"label\"])[:,0]}\npredictions = pd.DataFrame(dicts)\npredictions.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T16:49:35.956003Z","iopub.execute_input":"2024-08-13T16:49:35.956359Z","iopub.status.idle":"2024-08-13T16:49:36.815397Z","shell.execute_reply.started":"2024-08-13T16:49:35.956332Z","shell.execute_reply":"2024-08-13T16:49:36.814510Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de791396cb6941d2aa5961effa6c8ad3"}},"metadata":{}}]},{"cell_type":"code","source":"class DistillTrainingArguments(TrainingArguments):\n    def __init__(self, alpha = 0.4, T = 1.7, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.alpha = alpha\n        self.T = T\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:57:05.655527Z","iopub.execute_input":"2024-08-17T23:57:05.656654Z","iopub.status.idle":"2024-08-17T23:57:05.662103Z","shell.execute_reply.started":"2024-08-17T23:57:05.656606Z","shell.execute_reply":"2024-08-17T23:57:05.661183Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import Trainer\n\nclass DistillTrainer(Trainer):\n    def __init__(self, teacher_model = None, *args, **kargs):\n        super().__init__(*args, **kargs)\n        self.teacher_model = teacher_model\n    def compute_loss(self, model, inputs, return_outputs = False):\n        outputs_stu = model(**inputs)\n        # Extract cross-entropy loss and logits from student\n        loss_ce = outputs_stu.loss\n        logits_stu = outputs_stu.logits\n        # Extract logits from teacher\n        with torch.no_grad():\n            outputs_tea = self.teacher_model(**inputs)\n            logits_tea = outputs_tea.logits\n        # Soften probabilities and compute distillation loss\n        loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n        loss_kd = self.args.T ** 2 * loss_fct(\n        F.log_softmax(logits_stu / self.args.T,\n        dim=-1),\n        F.softmax(logits_tea / self.args.T, dim=-1))\n        # Return weighted student loss\n        loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n        \n        return (loss, outputs_stu) if return_outputs else loss\n\n  ","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:57:08.029477Z","iopub.execute_input":"2024-08-17T23:57:08.029852Z","iopub.status.idle":"2024-08-17T23:57:08.039813Z","shell.execute_reply.started":"2024-08-17T23:57:08.029822Z","shell.execute_reply":"2024-08-17T23:57:08.038856Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"student_ckpt = \"distilbert-base-uncased\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:57:55.779839Z","iopub.execute_input":"2024-08-17T23:57:55.780679Z","iopub.status.idle":"2024-08-17T23:57:55.784708Z","shell.execute_reply.started":"2024-08-17T23:57:55.780624Z","shell.execute_reply":"2024-08-17T23:57:55.783714Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return  AutoModelForSequenceClassification.from_pretrained(student_ckpt, num_labels = 2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:57:11.368166Z","iopub.execute_input":"2024-08-17T23:57:11.368532Z","iopub.status.idle":"2024-08-17T23:57:11.373070Z","shell.execute_reply.started":"2024-08-17T23:57:11.368499Z","shell.execute_reply":"2024-08-17T23:57:11.372117Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n\n\ndef black_box_function(alpha, T):\n    student_training_args = DistillTrainingArguments(\n         output_dir=\"new\", evaluation_strategy = \"epoch\",\n         num_train_epochs=5, learning_rate=2e-5,\n         per_device_train_batch_size=32,\n         per_device_eval_batch_size=32,\n         weight_decay=0.01,\n         push_to_hub=False,\n        disable_tqdm=False,\n        alpha = alpha,\n        T = T,\n         log_level=\"error\",\n         report_to = \"none\")\n\n    distilbert_trainer = DistillTrainer(model_init=model_init,\n        teacher_model=model, args=student_training_args,\n        train_dataset=new['train'],\n        eval_dataset=new['test'],\n        compute_metrics=compute_metrics, \n        tokenizer=tokenizer)\n\n    distilbert_trainer.train()\n    return distilbert_trainer.evaluate()[\"eval_accuracy\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:58:15.963493Z","iopub.execute_input":"2024-08-17T23:58:15.964134Z","iopub.status.idle":"2024-08-17T23:58:15.970878Z","shell.execute_reply.started":"2024-08-17T23:58:15.964100Z","shell.execute_reply":"2024-08-17T23:58:15.969876Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pbounds = {'alpha': (0.01, 0.9), 'T': (1, 3)}\n\noptimizer = BayesianOptimization(\n    f=black_box_function,\n    pbounds=pbounds,\n    random_state=21,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:58:16.927300Z","iopub.execute_input":"2024-08-17T23:58:16.928122Z","iopub.status.idle":"2024-08-17T23:58:16.933709Z","shell.execute_reply.started":"2024-08-17T23:58:16.928089Z","shell.execute_reply":"2024-08-17T23:58:16.932800Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"optimizer.maximize(\n    init_points=2,\n    n_iter=4,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T23:58:18.973202Z","iopub.execute_input":"2024-08-17T23:58:18.973892Z","iopub.status.idle":"2024-08-18T00:24:40.728563Z","shell.execute_reply.started":"2024-08-17T23:58:18.973860Z","shell.execute_reply":"2024-08-18T00:24:40.727708Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"|   iter    |  target   |     T     |   alpha   |\n-------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efa55bd5f8174bb5bee4488e4615f107"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5f68bbad7e49319584058138ef0469"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.164032</td>\n      <td>0.814183</td>\n      <td>0.815408</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.129942</td>\n      <td>0.833224</td>\n      <td>0.833503</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.125540</td>\n      <td>0.839790</td>\n      <td>0.839524</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.125678</td>\n      <td>0.841760</td>\n      <td>0.841396</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.129697</td>\n      <td>0.838477</td>\n      <td>0.838617</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m1         | \u001b[30m0.8385    | \u001b[30m1.097     | \u001b[30m0.2673    |\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.096790</td>\n      <td>0.814839</td>\n      <td>0.816000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.059633</td>\n      <td>0.831254</td>\n      <td>0.831874</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.045829</td>\n      <td>0.840446</td>\n      <td>0.840500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.044085</td>\n      <td>0.843729</td>\n      <td>0.843585</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.045776</td>\n      <td>0.835194</td>\n      <td>0.835388</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m2         | \u001b[30m0.8352    | \u001b[30m2.442     | \u001b[30m0.02924   |\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.259629</td>\n      <td>0.812869</td>\n      <td>0.814036</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.219488</td>\n      <td>0.835850</td>\n      <td>0.835993</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.213147</td>\n      <td>0.848326</td>\n      <td>0.847642</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.218762</td>\n      <td>0.839790</td>\n      <td>0.839524</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.225204</td>\n      <td>0.834537</td>\n      <td>0.834537</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m3         | \u001b[30m0.8345    | \u001b[30m1.828     | \u001b[30m0.4935    |\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.165043</td>\n      <td>0.814839</td>\n      <td>0.816055</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.131379</td>\n      <td>0.833880</td>\n      <td>0.834175</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.126987</td>\n      <td>0.840446</td>\n      <td>0.840161</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.127169</td>\n      <td>0.839790</td>\n      <td>0.839483</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.131195</td>\n      <td>0.838477</td>\n      <td>0.838617</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m4         | \u001b[30m0.8385    | \u001b[30m1.096     | \u001b[30m0.2712    |\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:13, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.372831</td>\n      <td>0.824032</td>\n      <td>0.824580</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.350039</td>\n      <td>0.842416</td>\n      <td>0.841949</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.357976</td>\n      <td>0.841760</td>\n      <td>0.841047</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.392122</td>\n      <td>0.829941</td>\n      <td>0.829960</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.397029</td>\n      <td>0.834537</td>\n      <td>0.834384</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m5         | \u001b[30m0.8345    | \u001b[30m1.0       | \u001b[30m0.9       |\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.378634</td>\n      <td>0.822062</td>\n      <td>0.822659</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.357024</td>\n      <td>0.840446</td>\n      <td>0.840161</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.359157</td>\n      <td>0.841760</td>\n      <td>0.841047</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.390769</td>\n      <td>0.830598</td>\n      <td>0.830559</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.395663</td>\n      <td>0.835194</td>\n      <td>0.835099</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"| \u001b[30m6         | \u001b[30m0.8352    | \u001b[30m3.0       | \u001b[30m0.9       |\n=================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"print(optimizer.max)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:25:51.468069Z","iopub.execute_input":"2024-08-18T00:25:51.468829Z","iopub.status.idle":"2024-08-18T00:25:51.474354Z","shell.execute_reply.started":"2024-08-18T00:25:51.468794Z","shell.execute_reply":"2024-08-18T00:25:51.473245Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{'target': 0.8384766907419566, 'params': {'T': 1.0974497616182546, 'alpha': 0.267307597212937}}\n","output_type":"stream"}]},{"cell_type":"code","source":"student_training_args_optimized = DistillTrainingArguments(\n         output_dir=\"new\", evaluation_strategy = \"epoch\",\n         num_train_epochs=5, learning_rate=2e-5,\n         per_device_train_batch_size=32,\n         per_device_eval_batch_size=32,\n         weight_decay=0.01,\n         push_to_hub=False,\n        disable_tqdm=False,\n        alpha = 0.26730759,\n        T = 1.09744,\n         log_level=\"error\",\n         report_to = \"none\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:31:55.869501Z","iopub.execute_input":"2024-08-18T00:31:55.870408Z","iopub.status.idle":"2024-08-18T00:31:55.905804Z","shell.execute_reply.started":"2024-08-18T00:31:55.870369Z","shell.execute_reply":"2024-08-18T00:31:55.904697Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"student_model = AutoModelForSequenceClassification.from_pretrained(student_ckpt, num_labels = 2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:40:01.499255Z","iopub.execute_input":"2024-08-18T00:40:01.500101Z","iopub.status.idle":"2024-08-18T00:40:01.780134Z","shell.execute_reply.started":"2024-08-18T00:40:01.500067Z","shell.execute_reply":"2024-08-18T00:40:01.779337Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"distilbert_trainer_optimized = DistillTrainer(model=student_model,\n teacher_model=model, args=student_training_args_optimized,\n train_dataset=new['train'],\neval_dataset=new['test'],\n compute_metrics=compute_metrics, \n tokenizer=tokenizer)\n\ndistilbert_trainer_optimized.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:40:15.800095Z","iopub.execute_input":"2024-08-18T00:40:15.800941Z","iopub.status.idle":"2024-08-18T00:44:31.722055Z","shell.execute_reply.started":"2024-08-18T00:40:15.800906Z","shell.execute_reply":"2024-08-18T00:44:31.721180Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [480/480 04:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.153502</td>\n      <td>0.819435</td>\n      <td>0.820420</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.131333</td>\n      <td>0.834537</td>\n      <td>0.834908</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.125620</td>\n      <td>0.844386</td>\n      <td>0.843774</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.125400</td>\n      <td>0.845043</td>\n      <td>0.844625</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.129810</td>\n      <td>0.839133</td>\n      <td>0.839041</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=480, training_loss=0.13355814615885417, metrics={'train_runtime': 255.438, 'train_samples_per_second': 119.207, 'train_steps_per_second': 1.879, 'total_flos': 480563262531288.0, 'train_loss': 0.13355814615885417, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"test_new = test_dataset.map(input_ids)\n\ndef predict(batch):\n    tensor = torch.tensor(batch[\"input_ids\"]).to(device)\n    tensor = tensor.unsqueeze(0)\n    outputs = student_model(tensor)\n    \n    return {\"label\": outputs.logits.argmax(-1).to(device)}\n\ntest_new = test_new.map(predict)\ndicts = {\"id\": test[\"id\"].values,\"target\":np.array(test_new[\"label\"])[:,0]}\npredictions = pd.DataFrame(dicts)\npredictions.to_csv(\"distillsubmission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:45:01.774576Z","iopub.execute_input":"2024-08-18T00:45:01.775469Z","iopub.status.idle":"2024-08-18T00:45:27.485710Z","shell.execute_reply.started":"2024-08-18T00:45:01.775432Z","shell.execute_reply":"2024-08-18T00:45:27.484788Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74920423f85045e8bc9b26a40c3ffe37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"499658443d024542bc9bcd809a9a5211"}},"metadata":{}}]},{"cell_type":"code","source":"predictions.to_csv(\"distillsubmission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T00:46:58.767958Z","iopub.execute_input":"2024-08-18T00:46:58.768312Z","iopub.status.idle":"2024-08-18T00:46:58.777331Z","shell.execute_reply.started":"2024-08-18T00:46:58.768276Z","shell.execute_reply":"2024-08-18T00:46:58.776549Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}